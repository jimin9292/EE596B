{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load training, validation, testing set from your preprocessed files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = pickle.load(open('cat_dog_train.p','rb'))\n",
    "x_valid, y_valid = pickle.load(open('cat_dog_valid.p','rb'))\n",
    "x_test = pickle.load(open('cat_dog_test.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "image_width = 227\n",
    "image_height = 227\n",
    "image_depth = 3\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 227, 227, 3], name = 'X')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_labels], name = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init=tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AlexNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlexNet(X):\n",
    "\n",
    "    # Reshape input to 4-D vector\n",
    "    input_layer = tf.reshape(X, [-1, 227, 227, 3]) # -1 adds minibatch support.\n",
    "\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=96, # Number of filters.\n",
    "      kernel_size=11, \n",
    "      strides=(4,4),\n",
    "      padding=\"SAME\", \n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv1 = tf.nn.local_response_normalization(conv1, depth_radius = 2, alpha = 0.00002, beta = 0.75, bias = 1)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3], strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=256, # Number of filters\n",
    "      kernel_size=5, # Size of each filter is 5x5\n",
    "      padding=\"SAME\", # No padding\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv2 = tf.nn.local_response_normalization(conv2, depth_radius = 2, alpha = 0.00002, beta = 0.75, bias = 1)\n",
    "    pool2 = tf.layers.average_pooling2d(inputs=conv2, pool_size=[3, 3], strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=384, # Number of filters\n",
    "      kernel_size=3, # Size of each filter is 5x5\n",
    "      padding=\"SAME\", # No padding\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    conv4 = tf.layers.conv2d(\n",
    "      inputs=conv3,\n",
    "      filters=384, # Number of filters\n",
    "      kernel_size=3, # Size of each filter is 5x5\n",
    "      padding=\"SAME\", \n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "      inputs=conv4,\n",
    "      filters=256, # Number of filters\n",
    "      kernel_size=3, # Size of each filter is 5x5\n",
    "      padding=\"SAME\", \n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Reshaping output into a single dimention array for input to fully connected layer\n",
    "    flatten = tf.layers.flatten(conv5)\n",
    "    #flatten = tf.reshape(pool3, shape=[-1, (224 // 2 ** 5) * (224 // 2 ** 5) * 256])\n",
    "\n",
    "    dense1 = tf.layers.dense(inputs=flatten, units=4096, activation=tf.nn.relu, kernel_initializer=he_init)\n",
    "    dense1 = tf.nn.dropout(dense1, keep_prob=0.1)\n",
    "\n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=4096, activation=tf.nn.relu, kernel_initializer=he_init)\n",
    "    dense2 = tf.nn.dropout(dense2, keep_prob=0.1)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dense2, units=2, kernel_initializer=he_init)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = AlexNet(X)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "\n",
    "# Convert our labels into one-hot-vectors\n",
    "#labels = tf.one_hot(indices=tf.cast(Y, tf.int32), depth=10)\n",
    "\n",
    "# Compute the cross-entropy loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                                 labels=Y))\n",
    "\n",
    "# Use adam optimizer to reduce cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# For testing and prediction\n",
    "predictions = tf.argmax(softmax, axis=1)\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and validation</h1>\n",
    "<h2>Train your model only 10 epochs</h2>\n",
    "<p style=\"font-size:20px\">1. Print out training accuracy and validation accuracy each training epoch</p>\n",
    "<p style=\"font-size:20px\">2. Print out training time each training epoch</p>\n",
    "<p style=\"font-size:20px\">3. Your goal is to reach 85% validation accuracy in 10 training epochs. If you reach that, you can perform testing, print out your test accuracy. Plot out the ten images with title that contains the probability of the labeled class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    " \n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        num_samples = x_train.shape[0]\n",
    "        num_batches = (num_samples // batch_size) + 1\n",
    "        epoch_cost = 0.\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        # Shuffle training data each epoch\n",
    "        #shuffle_index = np.random.permutation(num_samples)\n",
    "        #x_train_shuffled = x_train[shuffle_index]\n",
    "        #y_train_shuffled = y_train[shuffle_index]\n",
    "        \n",
    "        i = 0\n",
    "        while i < num_samples:\n",
    "            batch_x = x_train[i:i+batch_size,:]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "            i += batch_size\n",
    "\n",
    "            # Train on batch and get back cost\n",
    "            _, c = sess.run([train_op, cost], feed_dict={X:batch_x, Y:batch_y})\n",
    "            epoch_cost += (c/num_batches)\n",
    "            \n",
    "            #print(epoch_cost)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"Took %f s\" % ((end - start)))\n",
    "\n",
    "        # Get accuracy for validation\n",
    "        train_accuracy = accuracy.eval(\n",
    "            feed_dict={X:batch_x, Y:batch_y})\n",
    "        \n",
    "        valid_accuracy = accuracy.eval(\n",
    "            feed_dict={X:x_valid, Y:y_valid})\n",
    "        \n",
    "        first_ten_prediction = sess.run(softmax, feed_dict={X:x_test[:10]}) \n",
    "        first_ten_prediction = tf.nn.softmax(first_ten_prediction).eval()\n",
    "\n",
    "        print (\"Epoch {}: Cost: {}\".format(epoch+1, epoch_cost))\n",
    "        print(\"Training accuracy: {}\".format(train_accuracy))\n",
    "        print(\"Validation accuracy: {}\".format(valid_accuracy))\n",
    "        print(first_ten_prediction)\n",
    "\n",
    "    #test_accuracy = accuracy.eval(feed_dict={X:x_test, Y:y_test})\n",
    "    \n",
    "    #print(\"Testing accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_predictions = np.asarray([[0.40059516, 0.5994048],\n",
    " [0.73032343, 0.2696766 ],\n",
    " [0.62702996, 0.37297004],\n",
    " [0.35234484, 0.6476551 ],\n",
    " [0.26932785, 0.7306721 ],\n",
    " [0.7288512,  0.27114874],\n",
    " [0.6780232,  0.3219768 ],\n",
    " [0.26946265, 0.73053735],\n",
    " [0.51816213, 0.4818378 ],\n",
    " [0.73086053, 0.2691395 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[0, 0]) + \" Dog_prob=\" + str(first_ten_prediction[0, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[1, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[1, 0]) + \" Dog_prob=\" + str(first_ten_prediction[1, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[2, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[2, 0]) + \" Dog_prob=\" + str(first_ten_prediction[2, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[3, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[3, 0]) + \" Dog_prob=\" + str(first_ten_prediction[3, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[4, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[4, 0]) + \" Dog_prob=\" + str(first_ten_prediction[4, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[5, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[5, 0]) + \" Dog_prob=\" + str(first_ten_prediction[5, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[6, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[6, 0]) + \" Dog_prob=\" + str(first_ten_prediction[6, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[7, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[7, 0]) + \" Dog_prob=\" + str(first_ten_prediction[7, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[8, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[8, 0]) + \" Dog_prob=\" + str(first_ten_prediction[8, 1]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[9, :])\n",
    "plt.title(\"Cat_prob=\" + str(first_ten_prediction[9, 0]) + \" Dog_prob=\" + str(first_ten_prediction[9, 1]), fontsize = 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
