{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extract MNIST data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#get mnist data, with one_hot encoding, reshape = False (that means images are not flatten)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False,one_hot=True)\n",
    "#suppress warnings\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prepare training, validation and testing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "x_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "#pad images with 0s (28x28 to 32x32)\n",
    "# did it within lenet5 function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "epochs=10\n",
    "batch_size=256\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init=tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"X\")\n",
    "Y = tf.placeholder(tf.int64, [None, num_classes], name=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X):\n",
    "\n",
    "    # Reshape input to 4-D vector\n",
    "    input_layer = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # Padding the input to make it 32x32\n",
    "    padded_input = tf.pad(input_layer, [[0, 0], [2, 2], [2, 2], [0, 0]], \"CONSTANT\") \n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Output: 28 * 28 * 6\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=padded_input,\n",
    "      filters=6, # Number of filters.\n",
    "      kernel_size=5, # Size of each filter is 5x5.\n",
    "      padding=\"valid\", # No padding is applied to the input.\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # Output: 14 * 14 * 6\n",
    "    pool1 = tf.layers.average_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Output: 10 * 10 * 16\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=16, # Number of filters\n",
    "      kernel_size=5, # Size of each filter is 5x5\n",
    "      padding=\"valid\", # No padding\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Output: 5 * 5 * 16\n",
    "    pool2 = tf.layers.average_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Reshaping output\n",
    "    #pool2_flat = tf.reshape(pool2, [-1, 5 * 5 * 16])\n",
    "    pool2_flat = tf.layers.flatten(pool2)\n",
    "    \n",
    "    # Fully connected layer #1\n",
    "    dense1 = tf.layers.dense(inputs=pool2_flat, units=120, activation=tf.nn.relu,kernel_initializer=he_init)\n",
    "\n",
    "    # Fully connected layer #2\n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=84, activation=tf.nn.relu,kernel_initializer=he_init)\n",
    "\n",
    "    # Output layer\n",
    "    logits = tf.layers.dense(inputs=dense2, units=10, kernel_initializer=he_init)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-50d7be150c3b>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-50d7be150c3b>:20: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-50d7be150c3b>:37: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-50d7be150c3b>:40: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "logits = CNN(X)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "\n",
    "# Compute the cross-entropy loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                                 labels=Y))\n",
    "\n",
    "# Use adam optimizer to reduce cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# For testing and prediction\n",
    "predictions = tf.argmax(softmax, axis=1)\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validating, testing</h1>\n",
    "<h2>1. Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2. Print out training time on each epoch</h2>\n",
    "<h2>3. Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 20.331277 s\n",
      "Epoch 1: Cost: 0.22518405512321837\n",
      "Validation accuracy: 0.9793999791145325\n",
      "Took 20.257057 s\n",
      "Epoch 2: Cost: 0.056870429243805795\n",
      "Validation accuracy: 0.9865999817848206\n",
      "Took 20.225214 s\n",
      "Epoch 3: Cost: 0.04354925534666277\n",
      "Validation accuracy: 0.9908000230789185\n",
      "Took 20.126649 s\n",
      "Epoch 4: Cost: 0.03894906048554668\n",
      "Validation accuracy: 0.9868000149726868\n",
      "Took 20.160894 s\n",
      "Epoch 5: Cost: 0.029958994546905166\n",
      "Validation accuracy: 0.9865999817848206\n",
      "Took 20.116646 s\n",
      "Epoch 6: Cost: 0.025802759845676114\n",
      "Validation accuracy: 0.9876000285148621\n",
      "Took 20.169829 s\n",
      "Epoch 7: Cost: 0.02436856763020459\n",
      "Validation accuracy: 0.9900000095367432\n",
      "Took 20.129010 s\n",
      "Epoch 8: Cost: 0.025356484679938417\n",
      "Validation accuracy: 0.989799976348877\n",
      "Took 20.267200 s\n",
      "Epoch 9: Cost: 0.023807409167463017\n",
      "Validation accuracy: 0.989799976348877\n",
      "Took 20.118982 s\n",
      "Epoch 10: Cost: 0.023302058793257842\n",
      "Validation accuracy: 0.9879999756813049\n",
      "Testing accuracy: 0.9898999929428101\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    " \n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        num_samples = x_train.shape[0]\n",
    "        num_batches = (num_samples // batch_size) + 1\n",
    "        epoch_cost = 0.\n",
    "        \n",
    "        # Shuffle training data each epoch\n",
    "        shuffle_index = np.random.permutation(num_samples)\n",
    "        x_train_shuffled = x_train[shuffle_index]\n",
    "        y_train_shuffled = y_train[shuffle_index]\n",
    "        \n",
    "        i = 0\n",
    "        while i < num_samples:\n",
    "            batch_x = x_train_shuffled[i:i+batch_size,:]\n",
    "            batch_y = y_train_shuffled[i:i+batch_size]\n",
    "\n",
    "            i += batch_size\n",
    "\n",
    "            # Train on batch and get back cost\n",
    "            _, c = sess.run([train_op, cost], feed_dict={X:batch_x, Y:batch_y})\n",
    "            epoch_cost += (c/num_batches)\n",
    "            \n",
    "            #print(epoch_cost)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"Took %f s\" % ((end - start)))\n",
    "\n",
    "        # Get accuracy for validation\n",
    "        valid_accuracy = accuracy.eval(\n",
    "            feed_dict={X:x_validation, Y:y_validation})\n",
    "\n",
    "        print (\"Epoch {}: Cost: {}\".format(epoch+1, epoch_cost))\n",
    "        print(\"Validation accuracy: {}\".format(valid_accuracy))\n",
    "\n",
    "    test_accuracy = accuracy.eval(feed_dict={X:x_test, Y:y_test})\n",
    "    \n",
    "    print(\"Testing accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
