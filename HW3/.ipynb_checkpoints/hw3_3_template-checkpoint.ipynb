{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "In the <b>HW3_template</b> folder you will find `TSLA.csv`, `GOOGL.csv` and `DJI.csv` files. Use Pandas (You have used it in HW1) to retrieve the dataset. Use only <b>Open</b> price as your input. (You will train three models for three different stocks, don't mix these data together!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stocks = pd.read_csv('TSLA.csv')\n",
    "google_stocks = pd.read_csv('GOOGL.csv')\n",
    "dji_stocks = pd.read_csv('DJI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dji_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use_tesla = tesla_stocks['Open'].values\n",
    "data_to_use_google = google_stocks['Open'].values\n",
    "data_to_use_dji = dji_stocks['Open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_to_use_tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data\n",
    "You could use `MinMaxScaler` in `sklearn.preprocessing` to normalize the data between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_tesla = scaler.fit_transform(data_to_use_tesla.reshape(-1, 1))\n",
    "scaled_data_google = scaler.fit_transform(data_to_use_google.reshape(-1, 1))\n",
    "scaled_data_dji = scaler.fit_transform(data_to_use_dji.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaled_data_tesla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training, validation and testing data\n",
    "<p style=\"font-size:20px\">Since you will impelement a many-to-one Recurrent Neural Network model, every input data will have shape [batch_size, num_seq, input_size] and output data will have shape [batch_size, input_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(data, window_size):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    i = 0\n",
    "    while (i + window_size) <= len(data) - 1:\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "        \n",
    "        i += 1\n",
    "    assert len(X) ==  len(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = window_data(scaled_data_tesla, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = np.array(X[:-100])\n",
    "y_train = np.array(y[:-100])\n",
    "\n",
    "X_test = np.array(X[-100:])\n",
    "y_test = np.array(y[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TesnorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters used in the network\n",
    "\n",
    "batch_size = 7 \n",
    "window_size = 7 \n",
    "hidden_layer = 256 \n",
    "clip_margin = 4 \n",
    "learning_rate = 0.001 \n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
    "targets = tf.placeholder(tf.float32, [batch_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM weights\n",
    "#Weights for the input gate\n",
    "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
    "\n",
    "#weights for the forgot gate\n",
    "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
    "\n",
    "#weights for the output gate\n",
    "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
    "\n",
    "#weights for the memory cell\n",
    "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
    "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
    "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output layer weigts\n",
    "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
    "bias_output_layer = tf.Variable(tf.zeros([1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_cell(input, output, state):\n",
    "    \n",
    "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
    "    \n",
    "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
    "    \n",
    "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
    "    \n",
    "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
    "    \n",
    "    state = state * forget_gate + input_gate * memory_cell\n",
    "    \n",
    "    output = output_gate * tf.tanh(state)\n",
    "    return state, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "   \n",
    "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32) \n",
    "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
    "  \n",
    "    for ii in range(window_size):\n",
    "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
    "\n",
    "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
    "    \n",
    "loss = tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(loss, tf.trainable_variables())\n",
    "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    traind_scores = []\n",
    "    ii = 0\n",
    "    epoch_loss = []\n",
    "    while(ii + batch_size) <= len(X_train):\n",
    "        X_batch = X_train[ii:ii+batch_size]\n",
    "        y_batch = y_train[ii:ii+batch_size]\n",
    "        \n",
    "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
    "        \n",
    "        epoch_loss.append(c)\n",
    "        traind_scores.append(o)\n",
    "        ii += batch_size\n",
    "    if (i % 30) == 0:\n",
    "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "i = 0\n",
    "while i+batch_size <= len(X_test):\n",
    "    \n",
    "    o = session.run([outputs], feed_dict={inputs:X_test[i:i+batch_size]})\n",
    "    i += batch_size\n",
    "    tests.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_new = []\n",
    "for i in range(len(tests)):\n",
    "    for j in range(len(tests[i][0])):\n",
    "        tests_new.append(tests[i][0][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for i in range(2220):\n",
    "    if i >= 2122:\n",
    "        test_results.append(tests_new[i-2122])\n",
    "    else:\n",
    "        test_results.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 7))\n",
    "plt.plot(scaled_data_tesla[-100:], label='Original data')\n",
    "plt.plot(test_results[-100:], label='Testing data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "\n",
    "for testval in tests_new:\n",
    "    \n",
    "    test_samples.append(testval[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
