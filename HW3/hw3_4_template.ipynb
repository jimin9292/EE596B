{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from text_utils import TextLoader\n",
    "from tensorflow.contrib import rnn\n",
    "from char_rnn_model import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories, hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50 # sequence length\n",
    "batch_size = 60  # minibatch size\n",
    "num_epochs = 100 \n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "rnn_size = 128 # size of RNN hidden state (output dimension)\n",
    "num_layers = 2 #number of layers in the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using TextLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "(' ', 'e', 't', 'o', 'a', 'h', 's', 'n', 'r', 'i', '\\r', '\\n', 'l', 'd', 'u', 'm', 'y', ',', 'w', 'f', 'c', 'g', 'I', ':', 'b', 'p', 'A', '.', 'v', 'T', 'k', \"'\", 'S', 'E', 'O', 'N', 'R', 'L', ';', 'C', 'H', 'W', 'M', 'U', 'B', 'D', '?', 'F', '!', '-', 'G', 'P', 'Y', 'K', 'V', 'j', 'q', 'x', 'J', 'z', 'Q', 'Z', 'X', '3', '&', '[', ']', '$')\n"
     ]
    }
   ],
   "source": [
    "data_loader = TextLoader('', batch_size, seq_length)\n",
    "vocab_size = data_loader.vocab_size\n",
    "\n",
    "# size of the vocabs \n",
    "print(data_loader.vocab_size)\n",
    "\n",
    "# characters\n",
    "print(data_loader.chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Documents\\GitHub\\EE596B\\HW3\\char_rnn_model.py:54: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Documents\\GitHub\\EE596B\\HW3\\char_rnn_model.py:56: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"rnn\"):\n",
    "    model = LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss = 1.577\n",
      "epoch 1, train_loss = 1.504\n",
      "epoch 2, train_loss = 1.468\n",
      "epoch 3, train_loss = 1.451\n",
      "epoch 4, train_loss = 1.439\n",
      "epoch 5, train_loss = 1.429\n",
      "epoch 6, train_loss = 1.420\n",
      "epoch 7, train_loss = 1.413\n",
      "epoch 8, train_loss = 1.407\n",
      "epoch 9, train_loss = 1.400\n",
      "epoch 10, train_loss = 1.396\n",
      "epoch 11, train_loss = 1.391\n",
      "epoch 12, train_loss = 1.388\n",
      "epoch 13, train_loss = 1.385\n",
      "epoch 14, train_loss = 1.384\n",
      "epoch 15, train_loss = 1.382\n",
      "epoch 16, train_loss = 1.380\n",
      "epoch 17, train_loss = 1.378\n",
      "epoch 18, train_loss = 1.375\n",
      "epoch 19, train_loss = 1.373\n",
      "epoch 20, train_loss = 1.371\n",
      "epoch 21, train_loss = 1.368\n",
      "epoch 22, train_loss = 1.366\n",
      "epoch 23, train_loss = 1.365\n",
      "epoch 24, train_loss = 1.363\n",
      "epoch 25, train_loss = 1.362\n",
      "epoch 26, train_loss = 1.361\n",
      "epoch 27, train_loss = 1.359\n",
      "epoch 28, train_loss = 1.358\n",
      "epoch 29, train_loss = 1.357\n",
      "epoch 30, train_loss = 1.355\n",
      "epoch 31, train_loss = 1.354\n",
      "epoch 32, train_loss = 1.352\n",
      "epoch 33, train_loss = 1.351\n",
      "epoch 34, train_loss = 1.350\n",
      "epoch 35, train_loss = 1.348\n",
      "epoch 36, train_loss = 1.347\n",
      "epoch 37, train_loss = 1.346\n",
      "epoch 38, train_loss = 1.345\n",
      "epoch 39, train_loss = 1.344\n",
      "epoch 40, train_loss = 1.343\n",
      "epoch 41, train_loss = 1.342\n",
      "epoch 42, train_loss = 1.341\n",
      "epoch 43, train_loss = 1.341\n",
      "epoch 44, train_loss = 1.340\n",
      "epoch 45, train_loss = 1.339\n",
      "epoch 46, train_loss = 1.339\n",
      "epoch 47, train_loss = 1.338\n",
      "epoch 48, train_loss = 1.338\n",
      "epoch 49, train_loss = 1.337\n",
      "epoch 50, train_loss = 1.337\n",
      "epoch 51, train_loss = 1.336\n",
      "epoch 52, train_loss = 1.335\n",
      "epoch 53, train_loss = 1.335\n",
      "epoch 54, train_loss = 1.334\n",
      "epoch 55, train_loss = 1.334\n",
      "epoch 56, train_loss = 1.333\n",
      "epoch 57, train_loss = 1.333\n",
      "epoch 58, train_loss = 1.332\n",
      "epoch 59, train_loss = 1.331\n",
      "epoch 60, train_loss = 1.331\n",
      "epoch 61, train_loss = 1.330\n",
      "epoch 62, train_loss = 1.330\n",
      "epoch 63, train_loss = 1.329\n",
      "epoch 64, train_loss = 1.329\n",
      "epoch 65, train_loss = 1.328\n",
      "epoch 66, train_loss = 1.328\n",
      "epoch 67, train_loss = 1.327\n",
      "epoch 68, train_loss = 1.327\n",
      "epoch 69, train_loss = 1.327\n",
      "epoch 70, train_loss = 1.326\n",
      "epoch 71, train_loss = 1.326\n",
      "epoch 72, train_loss = 1.325\n",
      "epoch 73, train_loss = 1.325\n",
      "epoch 74, train_loss = 1.325\n",
      "epoch 75, train_loss = 1.324\n",
      "epoch 76, train_loss = 1.324\n",
      "epoch 77, train_loss = 1.324\n",
      "epoch 78, train_loss = 1.323\n",
      "epoch 79, train_loss = 1.323\n",
      "epoch 80, train_loss = 1.323\n",
      "epoch 81, train_loss = 1.322\n",
      "epoch 82, train_loss = 1.322\n",
      "epoch 83, train_loss = 1.322\n",
      "epoch 84, train_loss = 1.322\n",
      "epoch 85, train_loss = 1.321\n",
      "epoch 86, train_loss = 1.321\n",
      "epoch 87, train_loss = 1.321\n",
      "epoch 88, train_loss = 1.321\n",
      "epoch 89, train_loss = 1.321\n",
      "epoch 90, train_loss = 1.320\n",
      "epoch 91, train_loss = 1.320\n",
      "epoch 92, train_loss = 1.320\n",
      "epoch 93, train_loss = 1.320\n",
      "epoch 94, train_loss = 1.320\n",
      "epoch 95, train_loss = 1.319\n",
      "epoch 96, train_loss = 1.319\n",
      "epoch 97, train_loss = 1.319\n",
      "epoch 98, train_loss = 1.319\n",
      "epoch 99, train_loss = 1.319\n",
      "The braggation, double amend\n",
      "Of in us purnons:\n",
      "'Tis \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(num_epochs): \n",
    "        \n",
    "        # implement slowly decaying learning rate per epoch\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        data_loader.reset_batch_pointer()\n",
    "        state = sess.run(model.initial_state) \n",
    "        \n",
    "        for b in range(data_loader.num_batches):\n",
    "            \n",
    "            x, y = data_loader.next_batch()\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}\n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            \n",
    "        print(\"epoch {}, train_loss = {:.3f}\" \\\n",
    "                .format(e, train_loss))\n",
    "    \n",
    "    # Generating text\n",
    "    \n",
    "    with tf.variable_scope(\"rnn\", reuse=True):\n",
    "        \n",
    "        sample_model = LSTM(sample=True)\n",
    "\n",
    "        print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=50, prime='The ', sampling_type=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
