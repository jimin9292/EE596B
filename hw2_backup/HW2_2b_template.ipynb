{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "import load_cifar_template as lct\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_1,training_labels_1 = pickle.load(open('preprocess_batch_1.p','rb'))\n",
    "training_features_2,training_labels_2 = pickle.load(open('preprocess_batch_2.p','rb'))\n",
    "training_features_3,training_labels_3 = pickle.load(open('preprocess_batch_3.p','rb'))\n",
    "training_features_4,training_labels_4 = pickle.load(open('preprocess_batch_4.p','rb'))\n",
    "training_features_5,training_labels_5 = pickle.load(open('preprocess_batch_5.p','rb'))\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p','rb'))\n",
    "test_features, test_labels = pickle.load(open('preprocess_testing.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Hyper-perparmeter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.0001\n",
    "#number of epochs\n",
    "epochs = 10\n",
    "#number of batch_size\n",
    "batch_size = 64\n",
    "\n",
    "#network parameters\n",
    "n_hidden_1 = 2048\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_3 = 512\n",
    "num_input = training_features_1[0, :].shape[0] * training_features_1[0, :].shape[1] * training_features_1[0, :].shape[2]\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_1d(training_features):\n",
    "    \n",
    "    features_reshaped = []\n",
    "\n",
    "    for image in training_features:\n",
    "        \n",
    "        arr = np.array([])\n",
    "\n",
    "        r = image[:, :, 0].reshape(1024)\n",
    "        g = image[:, :, 1].reshape(1024)\n",
    "        b = image[:, :, 2].reshape(1024)\n",
    "\n",
    "        arr = np.concatenate((r,g,b))\n",
    "        \n",
    "        features_reshaped.append(arr)\n",
    "\n",
    "    return np.stack(features_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = reshape_1d(training_features_1)\n",
    "train_2 = reshape_1d(training_features_2)\n",
    "train_3 = reshape_1d(training_features_3)\n",
    "train_4 = reshape_1d(training_features_4)\n",
    "train_5 = reshape_1d(training_features_5)\n",
    "\n",
    "train_features = np.vstack([train_1, train_2, train_3, train_4, train_5])\n",
    "train_labels = np.vstack([training_labels_1, training_labels_2, training_labels_3, training_labels_4, training_labels_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = reshape_1d(test_features)\n",
    "valid_features = reshape_1d(valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jimin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#tf graph input\n",
    "X = tf.placeholder(tf.float32,[None,num_input],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "#Layers weight & bias\n",
    "weights = {\n",
    "    'W1': tf.Variable(initializer([num_input, n_hidden_1]),name='W1'),\n",
    "    'W2': tf.Variable(initializer([n_hidden_1, n_hidden_2]),name='W2'),\n",
    "    'W3': tf.Variable(initializer([n_hidden_2, n_hidden_3]),name='W3'),\n",
    "    'Wout': tf.Variable(initializer([n_hidden_3, num_classes]),name='Wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros(shape=[n_hidden_1]),name='b1'),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[n_hidden_2]),name='b2'),\n",
    "    'b3': tf.Variable(tf.zeros(shape=[n_hidden_3]),name='b3'),\n",
    "    'bout': tf.Variable(tf.zeros(shape=[num_classes]),name='bout')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a neural net model\n",
    "def neural_net(x):\n",
    "    layer_1_out = tf.nn.elu(tf.add(tf.matmul(x,weights['W1']),biases['b1']))\n",
    "    layer_2_out = tf.nn.elu(tf.add(tf.matmul(layer_1_out,weights['W2']),biases['b2']))\n",
    "    layer_3_out = tf.nn.elu(tf.add(tf.matmul(layer_2_out,weights['W3']),biases['b3']))\n",
    "    out = tf.add(tf.matmul(layer_3_out,weights['Wout']),biases['bout'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define cost andoptimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted labels\n",
    "logits = neural_net(X)\n",
    "\n",
    "#define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y),name='loss')\n",
    "#define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "#compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "\n",
    "#compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n",
    "\n",
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and testing</h1>\n",
    "<h2>1.Print out validation accuracy after each training poch</h2>\n",
    "<h2>2.Print out training time you spend on each epoch</h2>\n",
    "<h2>3.Print out testing accuracy in the end</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 51.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, Accuracy_train= 0.297\n",
      "epoch 0, Accuracy_valid= 0.398\n",
      "1.8087828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Accuracy_train= 0.406\n",
      "epoch 1, Accuracy_valid= 0.440\n",
      "1.668611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 51.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, Accuracy_train= 0.453\n",
      "epoch 2, Accuracy_valid= 0.467\n",
      "1.5352414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, Accuracy_train= 0.469\n",
      "epoch 3, Accuracy_valid= 0.482\n",
      "1.4156961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, Accuracy_train= 0.547\n",
      "epoch 4, Accuracy_valid= 0.492\n",
      "1.3298855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, Accuracy_train= 0.609\n",
      "epoch 5, Accuracy_valid= 0.500\n",
      "1.2505876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, Accuracy_train= 0.656\n",
      "epoch 6, Accuracy_valid= 0.501\n",
      "1.1515931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, Accuracy_train= 0.688\n",
      "epoch 7, Accuracy_valid= 0.499\n",
      "1.0557438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, Accuracy_train= 0.750\n",
      "epoch 8, Accuracy_valid= 0.505\n",
      "0.96015406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 703/703 [00:13<00:00, 52.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, Accuracy_train= 0.781\n",
      "epoch 9, Accuracy_valid= 0.505\n",
      "0.8844078\n",
      "Training finished!\n",
      "Testing Accuracy: 0.5052\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        #fetch batch\n",
    "        for batch_x, batch_y in lct.mini_batch(train_features, train_labels, batch_size):\n",
    "    \n",
    "            sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "            \n",
    "        acc_train = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "        acc_valid = sess.run(accuracy,feed_dict={X:valid_features, Y:valid_labels})\n",
    "        L = sess.run(loss,feed_dict={X:batch_x, Y:batch_y})\n",
    "        print(\"epoch \"+str(i)+\", Accuracy_train= {:.3f}\".format(acc_train))\n",
    "        print(\"epoch \"+str(i)+\", Accuracy_valid= {:.3f}\".format(acc_valid))\n",
    "        print(L)\n",
    "    \n",
    "    print(\"Training finished!\")\n",
    "    \n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X:test_features, Y:test_labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
